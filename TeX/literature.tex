\section{Relation to Literature}
\label{sec:lit}
The concept of resource-limited cognition, positing that humans have finite cognitive resources for processing information and performing tasks, provides the foundation for optimization of resources amongst humans and technology. Seminal work by \cite{norman1975data} differentiated between data-limited and resource-limited processes, arguing that performance is often constrained by the availability of cognitive resources, not just information. \cite{kahneman1973attention} influential model of attention and effort further established that cognitive capacity is a limited resource that must be strategically allocated. These studies provided the groundwork for understanding cognitive resources as analogous to other scarce resources, subject to allocation decisions that impact performance. This perspective is further reinforced by more recent psychological research exploring the implications of cognitive resource limitations in various domains \citep{engle2018working}.

While the core principle of resource limitation is widely accepted, its precise implications for decision-making remain an active area of research. For instance, \cite{deck2015effect} demonstrated that individuals under high cognitive load tend to rely more on heuristics, indicating suboptimal resource allocation, while \cite{hagger2010ego} showed that cognitive resource depletion can impair self-regulation. These findings suggest that cognitive limitations can lead to deviations from purely rational behavior. Although alternative perspectives on cognitive resources exist \citep{tuk2015propagation,inzlicht2021integrating}, they do not negate the fundamental constraint of limited cognitive capacity \citep{palma2018self}. Rather, scarce cognitive resources underscore the inherent limitations of human cognition.

Complementing the psychological perspective, economic models have long recognized the importance of resource allocation under constraints. \cite{becker1965theory}, modelling the allocation of time, highlighted the trade-off between labor and leisure, mirroring the tension between direct task execution and AI development in the model presented here. Modern economic theory, particularly the concept of opportunity cost, emphasizes constrained optimization as a central element of decision-making, with applications ranging from consumer choice to firm behavior \citep{varian1992microeconomic}. Behavioral economics further develops these principles by demonstrating how cognitive limitations influence economic choices \citep{thaler2016behavioral}. For example, research on intertemporal choice highlights the challenges of resource allocation when decisions involve trade-offs between immediate and future benefits, a challenge central to the allocation of effort between direct tasks and AI development \citep{loewenstein1992anomalies,kim2019effect}.

While research on human cognition continues, important progress has also been made in computational optimization for AI systems, notably in hyperparameter optimization aimed at determining the best parameter configurations for machine learning models. Techniques such as Bayesian optimization \citep{snoek2012practical}, evolutionary algorithms \citep{real2019regularized}, and reinforcement learning \citep{elsken2019neural} have been used to automate this process, aiming to minimize computational cost while maximizing model performance. These methods often treat computational resources as the primary constraint, without explicitly considering the interaction with human cognitive resources.

Research on the management of computational resources in large-scale machine learning systems, particularly GPU utilization, focuses on dynamic resource allocation strategies \citep{grandl2014multi} and optimizing the placement and scheduling of deep learning workloads across heterogeneous GPU clusters \citep{mirhosseini2017binochs}. These studies are crucial for maximizing the efficiency of AI systems but often operate under the assumption of a fixed amount of available computing power. Other related work considers job scheduling on large-scale computing clusters, addressing the allocation of finite resources (e.g., CPU cores, memory) to a set of competing jobs, each with specific requirements. Techniques such as integer programming \citep{mittal2013general} and online learning \citep{li2022optimizing} have been used to optimize scheduling in dynamic, heterogeneous computing environments.

While these efforts significantly advance the understanding of resource allocation in AI systems, they often treat computational resources in isolation, without explicitly considering the interaction with human cognitive capacity. This motivates the present framework, which integrates both human and computational resource constraints into a unified model. Although many of these studies assume that the resource constraints faced by firms are exogenously given, they do not consider how firms or individuals might endogenously alter those constraints. In Section 3, details are provided on how these AI-focused methods help inform the production function approach, wherein the agent’s AI-related returns exhibit strict concavity.

Diminishing returns in AI development, where additional investments yield progressively smaller benefits, manifest in various ways. Well-established in economics \citep{dixit1990optimization}, it is captured mathematically by the strict concavity of the production function. For instance, \cite{kaplan2020scaling} demonstrated that scaling up deep learning models leads to diminishing improvements in accuracy, especially when training data is limited. Similarly, \cite{snoek2012practical} found that gains from hyperparameter tuning taper off, indicating a concave relationship between optimization effort and model performance.

Empirical evidence of diminishing returns is also found in robotic process automation (RPA) \citep{syed2020robotic}. Studies suggest that while initial RPA deployments yield significant cost savings, subsequent automation projects tackle more complex tasks, resulting in decreasing marginal benefits. This concave production function perspective clarifies why each additional unit of effort toward AI enhancement eventually yields smaller marginal gains. Moreover, recent work suggests that incremental AI deployments may yield better returns on investment than large-scale, simultaneous implementations \citep{davenport2018artificial}. Incorporating strict concavity in the model therefore aligns with both theoretical and observed patterns, ensuring that interior solutions are feasible rather than overshadowed by corner solutions.

The framework builds upon the mathematical foundations of constrained optimization, particularly first and second-order conditions for optimality, to derive analytical results. The method of Lagrange multipliers, a fundamental technique for finding local maxima and minima subject to equality constraints, has been extensively studied \citep{flaam2008slopes,jie2021computing}. The Lagrangian function incorporates the constraints into the objective function, and the first-order necessary conditions for optimality state that the gradient of the Lagrangian must be zero at an optimum. The second-order conditions, involving the Hessian matrix of the Lagrangian, are essential for determining whether a stationary point is a maximum, minimum, or saddle point \citep{hallak2020finding}.

Modern optimization theory has refined these concepts and applied them to machine learning contexts where non-convexity is prevalent \citep{dauphin2014identifying}. By leveraging these methods, it is formally shown that the marginal products of direct labor and AI enhancement must align at an interior optimum, provided strict concavity of the AI production function. Under these conditions, negative definiteness guarantees that the solution is unique rather than degenerate. \cite{sekeris2024conflict}, \cite{dehm2023non}, and others offer comprehensive treatments of such second-order analyses in convex and non-convex optimization alike.

While the literature on resource-limited cognition \citep{norman1975data,kahneman1973attention} and AI resource allocation \citep{snoek2012practical, gu2022ai} is extensive, there exists a lack of constrained optimization frameworks that integrate both human cognitive limitations and AI development efforts while permitting an endogenous increase in constraints through investment. Research on human-AI collaboration has begun to explore this intersection \citep{cappelli2023artificial,westby2023collective}, but tends to focus on qualitative aspects rather than rigorous models of resource allocation. Moreover, many existing quantitative models treat human and machine capabilities as static and exogenous, overlooking the dynamic interplay that arises as an agent devotes effort to AI enhancement.

This paper addresses this gap by proposing a novel theoretical model that treats cognitive and computational resources as a unified budget which can be augmented through investment in AI capability. By proving that the relationship between direct human effort and AI performance must be strictly concave under standard assumptions imposed in optimization theory, the framework formalizes that the optimum involves distributing resources across both direct labor and AI development. This level of formalization and analytical rigor is currently lacking in prior studies on human-AI interaction. As detailed in Section~\ref{sec:Framework}, the agent’s decision problem is defined, showing how diminishing returns from AI appear via concavity.