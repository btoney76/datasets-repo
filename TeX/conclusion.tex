\section{Conclusion}
\label{sec:con}
This paper illustrates a novel theoretical framework for analyzing the optimal allocation of effort between direct human labor and the enhancement of AI systems in the context of completing a focal task. By characterizing cognitive resources and computational capacity as a scarce resource in the context of AI adoption, the model integrates insights from the psychology of resource-limited cognition, the economics of constrained optimization, and the computational literature on AI resource allocation. The framework formalizes the trade-off between investing effort directly in a task and investing in AI tools that can enhance productivity. In particular, Proposition~\ref{pro:foc} proves that an interior solution to the decision problem~\ref{eq:problem} occurs when the marginal product of direct effort equals the marginal product of AI enhancement across all available AI systems. Proposition~\ref{pro:soc} follows this result up by proving that for this unique solution to be a maximum, the AI production function \textit{must} be strictly concave.

The model yields several key insights. First, it demonstrates that the optimal allocation of effort towards AI systems is fundamentally determined by the properties of the AI production technology, not the specific functional form of the agent’s utility function. This highlights the crucial role of technological advancements and education in shaping human-AI collaboration. Second, it provides a theoretical foundation for understanding why a balanced approach combining direct human input with AI assistance is often optimal in AI development. This aligns with empirical observations of diminishing returns in various AI applications, such as model scaling and hyperparameter tuning. Third, the framework can be extended to analyze how changes in AI technology or multiple tasks influence the agent’s allocation. As AI becomes more capable, the model suggests increased reliance on AI, but only to a point, due to diminishing returns and the need to address tasks that cannot be automated.

Moreover, these theoretical findings invite empirical testing in specific AI development contexts, for instance by gathering data on how teams distribute hours between direct labor and AI refinement. Such an empirical approach could more precisely illustrate the concavity of the AI production function in real-world scenarios. Future research may also incorporate behavioral phenomenon such as process utility \citep{frey2005beyond}, dynamics \citep{bellman1952theory}, or uncertain AI performance. For example, researchers could expand the current framework into a multi-period environment to allow for sequential AI enhancement decisions towards optimizing long-run productivity, capturing the trade-off between effort spent learning AI today and increases in productivity due to AI adoption tomorrow \citep{arrow1962economic,argote2011organizational}. A deeper understanding of these issues is essential for maximizing AI’s benefits while preserving human expertise and oversight in the AI-driven workplace. The framework presented here stands as a rigorous analytical exploration for examining these fundamental trade-offs and optimizing the synergy between human and artificial intelligence.
