\section{Introduction}
The rapid advancement and deployment of artificial intelligence (AI) technologies have ushered in a new era of computational capabilities, transforming industries and reshaping the nature of work \citep{hoffmann2024generative}. Although significant strides have been made in areas such as natural language processing \citep{vaswani2017attention}, computer vision \citep{he2016deep}, and predictive analytics \citep{bzdok2018machine}, the high-dimensional nature of these systems presents critical challenges for everyday decision-makers. Specifically, the use and implementation of sophisticated AI systems require careful orchestration of cognitive resources by everyday professionals, including effort, time, and human capital. The inefficient use of AI systems can lead to spiraling operational costs, delayed deployment cycles, inconsistent outputs, or even project failure \citep{heath2019prediction}. Thus, optimizing the balance between leveraging human ingenuity and harnessing the power of AI is a central concern of modern computational optimization and a critical determinant of success in the increasingly AI-driven economy \citep{furman2019ai}.

This challenge of resource allocation in the context of AI development stems from the well-established literature on resource-limited cognition in psychology and economics. Seminal work by \cite{simon1955behavioral}, \cite{kahneman1973attention}, and \cite{baumeister2018ego} established that humans possess finite cognitive bandwidth, a constraint that necessitates strategic allocation of attention and effort when managing complex tasks. Because individuals must judiciously allocate their limited cognitive resources to maximize productivity \citep{norman1975data}, organizations and individuals developing AI systems must navigate how to best allot limited resources between direct human labor on a focal task and investment in building and refining AI capacity to enhance productivity on that task. This decision is particularly salient in AI development, where tasks such as training large-scale models, curating specialized datasets, and fine-tuning algorithmic pipelines demand significant up-front effort, including, but not limited to, prompt engineering, model selection, and performance evaluation \citep{amodei2016concrete,mallen2024balancing}.

This paper models the trade-off between AI adoption and completing tasks unassisted with a constrained optimization approach, outlining second-order conditions that ensure a unique interior solution in which both direct labor and AI enhancements coexist across two tasks. In this decision problem, agents must confront the trade-off between deploying AI systems and completing the task on their own behalf. The model treats cognitive and computational resources as a scarce resource from which a rationally inattentive agent strategically allocates effort \citep{sims2003implications,caplin2015revealed,dewan2020estimating,mackowiak2023rational}. In particular, the agent’s objective is to maximize a strictly increasing and quasiconcave utility function; the value of which is determined by the performance of the agent in two concurrent tasks (task 1 and task 2). In task 1, agents may exert their own effort to increase performance, or delegate this task to upwards of $n$ AI systems; in task 2, the agent must complete the task unassisted. This allocation is subject to a finite cognitive budget and a production technology underlying AI productivity, reflecting the realities of rational inattention and the limits to Moore's Law.\footnote{Moore's Law stipulates that there is an exponential increase in task performance over time due to advances in technology \citep{moore1998cramming}. However, Moore's law hasn't held in recent time \citep{waldrop2016chips}, such as with quantum computing \citep{powell2008quantum}.} Crucially, the agent must expend cognitive effort to deploy the $n$ AI systems with prompt engineering \citep{giray2023prompt}, leading to a trade-off between direct effort and AI enhancement.

The contribution of this paper is the presentation of a parsimonious framework formalizing the allocation decision between direct human effort and investment in AI capability. Unlike existing studies that often treat human and computational resources in isolation, this model integrates these two concepts into a unified framework, revealing the critical interplay between cognitive limitations and AI adoption. Under the standard conditions of strict monotonicity and quasi-concavity of the utility function, it is proven here that a unique interior optimum \textit{can only exist} if the AI production function is strictly concave, representing the agent's diminishing returns to AI enhancement. This interior solution is characterized by the equalization of the marginal product of direct effort and the marginal product of AI enhancements. Notably, the results demonstrate that the adoption of AI by the agent is determined by the properties of the AI production function, not the specific form of the utility function, underscoring the central role of technological constraints in shaping optimal resource allocation in AI development.

This framework provides a powerful tool for analyzing the trade-offs inherent in human-AI collaboration, with implications that extend beyond theoretical considerations. By revealing the conditions under which a balanced approach is optimal, the model offers practical insights for individuals, teams, and organizations seeking to maximize productivity in AI-related endeavors. For instance, these findings can inform the design of AI development workflows in contexts such as healthcare, where AI diagnostics complement physicians’ efforts \citep{lammermann2024managing}. Moreover, these results can help policy makers develop safeguards ensuring at least \textit{some} human oversight is involved as AI is inevitably adopted by countless sectors in the economy \citep{agrawal2019economics}. The findings also resonate with broader questions about the future of work in the age of AI, highlighting the enduring importance of human expertise even as AI systems become increasingly sophisticated and integrated into our everyday lives.

The remainder of the paper is organized as follows. Section~\ref{sec:lit} reviews the relevant literature in psychology, economics, and computer science, explicitly noting how each strand informs the forthcoming theoretical model. Section~\ref{sec:Framework} presents the formal model of effort allocation. Section~\ref{sec:dis} provides a discussion with a practical example within different production technologies, applying the model to a simplified scenario of a medical doctor using AI tools, with additional remarks on how parameter changes influence allocations. Section~\ref{sec:con} offers concluding remarks and avenues for future research, including possible empirical tests of the model’s predictions.